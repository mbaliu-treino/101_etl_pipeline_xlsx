{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ETL with Python - Manipulating Large Masses of Data"
      ],
      "metadata": {
        "id": "qywvZXStwbTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEMA**: uma organização recebe um conjunto de dados de um relatório de forma constante e é esperado que eles sejam organizados em um painel que sintetize todos eles de uma maneira clara. Esses dados de assinaturas são gerados diariamente e representam os produtos gerados por cada sistema distribuído em cada país. Como consequência, eles não possuem a mesma padronização.\n",
        "\n",
        "Ao final será entregue uma aplicação que faz a carga de arquivos XLSX em Bancos de Dados.\n",
        "\n",
        "Este estudo mostra **maturidade do processo** e **a visibilidade que se tem sobre os dados**.\n",
        "\n",
        "O que será aprendido:\n",
        "\n",
        "* **Organização de um projeto de Tratamentos de Dados**\n",
        "    * Organização de as pastas\n",
        "    * Criação de ambiente de execução (venv)\n",
        "\n",
        "* Etapas de dados\n",
        "* Conectar nos Bancos de Dados\n",
        "* Garantir a confiabilidade dos dados\n",
        "* Garantir a rastreabilidade dos dados\n",
        "* Desenhar esquemas (tldraw - extensão no VSCode)\n"
      ],
      "metadata": {
        "id": "PFT8ihsGHOtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCEITOS PARA ENTREVISTA**\n",
        "\n",
        "Para demonstrar MATURIDADE e CONHECIMENTO DO SENTIDO das pequenas partes.\n",
        "\n",
        "Muitas vezes, em entrevistas técnicas é comum a pesso achegar com ocódigo pronto. Muitas vezes é interessante explicar os principais conceitos (porque usar uma determinada solução? Como ela funciona? Para uso de VENV, organização do projeto e camadas de dados). **Demonstrar que sabe fazer o simples bem feito**.\n",
        "\n",
        "Então saber falar sobre o desenvolvimento de SOLUÇÕES e não somente de CÓDIGOS."
      ],
      "metadata": {
        "id": "2Yu3x_CmFdiq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regras do Tratamento de dados**\n",
        "\n",
        "* Prezar pela confiabilidade e rastreabilidade dos dados"
      ],
      "metadata": {
        "id": "5TYaiNLdJ9EN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Camadas de Armazenamento**\n",
        "\n",
        "* RAW e READY\n",
        "* BRONZE, SILVER e GOLD"
      ],
      "metadata": {
        "id": "mnw2D--qxBCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ambiente Virtual Execução/Desenvolvimento**"
      ],
      "metadata": {
        "id": "DF-Bg-2AxQVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ETL de Dados**\n",
        "\n",
        "* cookiecutter - módulo de python\n",
        "\n"
      ],
      "metadata": {
        "id": "nfgBk0scxEic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UTM tag**\n",
        "\n",
        "UTM (Urchin Tracking Module ou Módulo de Rastreamento Urchin) é uma extensão de link de rastreamento que serve para entender a origem do tráfego.\n",
        "\n",
        "Através da UTM, é possível saber onde foi publicado e qual o conteúdo e campanha veiculados a determinado link"
      ],
      "metadata": {
        "id": "umdFmLw6Uzzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TAREFAS\n",
        "\n",
        "* Consolidar diversos arquivos de planilhas em uma única fonte\n",
        "    * Extrair informações de strings\n",
        "    * Rastreabildiade dos dados - indicar qual a origem dos dados"
      ],
      "metadata": {
        "id": "XdPs31iATkSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROTEIRO DE PROJETO\n",
        "\n",
        "1. <font color=orange><b>Iniciar um Projeto do Zero</b></font>\n",
        "    1. Abrir pasta\n",
        "        * `C:/www/python`\n",
        "    2. Nova pasta para o Projeto\n",
        "        * `mkdir make-data-netflix`\n",
        "    3. Abrir o VSCode na pasta\n",
        "        * `code make-data-netflix`\n",
        "2. <font color=orange><b>Documentação</b></font>\n",
        "    1. Crição de Pasta\n",
        "        * `mkdir docs`\n",
        "        * `cd docs`\n",
        "        * `cat hot-to.md`\n",
        "3. <font color=orange><b>Ambiente de Execução</b></font>\n",
        "    1. Criação do ambiente\n",
        "        * `python -m venv .venv`\n",
        "    2. Ativação do ambiente\n",
        "        * `.venv/Scripts/activate`\n",
        "    3. Instalação de dependências\n",
        "        * `pip install pandas, openpyxl, xlswriter, requests, polars`\n",
        "        * `xlswriter` é mais performático na hora de escrever e permite operar de maneira mais atômica.\n",
        "        * `pip install -r requirements.txt`\n",
        "        * `poetry`\n",
        "    4. Git\n",
        "        * `.gitignore`\n",
        "            * adicionar a pasta `src/data/raw/*`\n",
        "            * adicionar a pasta `src/data/ready/*`\n",
        "3. <font color=orange><b>Preparação</b></font>\n",
        "    1."
      ],
      "metadata": {
        "id": "M3PPpIpdYrae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Repositório de dados](https://www.youtube.com/redirect?event=live_chat&redir_token=QUFFLUhqbjFNdkpmNGhMTzROX2lJWGhXMUVYOW0xZWFtUXxBQ3Jtc0ttbUphNDV1dklmUEE4VjlnTWpONTVGSV8zeHZ5UG9CVWlHRWlfM1lvc3B5OV9FXzVkT2lyVk9LYWZqX3d3OVJVRWhZUDNNVFEtVWpObWxpWXlockhNbDN5WmZWUFBSLXdYRkJIaUduZFJCTE9VUTZ0RQ&q=https%3A%2F%2Fgithub.com%2Fdigitalinnovationone%2Fnetflix-dataset%2Ftree%2Fmain%2Fraw)"
      ],
      "metadata": {
        "id": "n6wk8PJGeT4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estrutura de Projeto de Tratamento de Dados\n",
        "\n",
        "* `src`\n",
        "    * _Tudo dentro do source é o código-fonte ou arquivos de textos, imagens etc. Tudo que estiver fora da `src` ou é documentação ou é configuração_\n",
        "    * `data`\n",
        "        * `raw`: dados brutos sem qualquer alteração\n",
        "        * `ready`: dados que já passaram por alguns script de tratamento do projeto. Então é onde os dados refinados são armazenados.\n",
        "    * `main.py`: se for só um arquivo ou uma aplicação inicial que chama todas as outras é possível usar um único arquivo.\n",
        "    * [`scripts`]: pasta opcional para quando hpa mais do que um único arquivo de execução da aplicação. Isso serve para separar a camada de dados da camada de códigos.\n",
        "\n",
        "\n",
        "Uma estrutura de projeto de API não é igual a uma estrutura de projeto de dados\n",
        "\n",
        "\"Transformação de data raw em dados refinados de negócios\""
      ],
      "metadata": {
        "id": "rah-9LqhdVSP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GISZcLz7vvJF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Caminho para ler o caminho\n",
        "folder_path = os.path.join(os.getcwd(), 'src', 'data', 'raw')\n",
        "\n",
        "# Lista de arquivos\n",
        "glob_unix_pattern = os.path.join(folder_path, '*.xlsx')\n",
        "excel_files = glob.glob( glob_unix_pattern )\n",
        "\n",
        "if not excel_files:\n",
        "    print('No file found in the specified folder')\n",
        "    raise ValueError('No file found in the specified folder')\n",
        "else:\n",
        "    # Dataframe - data in memory\n",
        "    dfs = []\n",
        "\n",
        "    for excel_file in excel_files:\n",
        "        try:\n",
        "            # Leitura de XLSX\n",
        "            df_temp = pd.read_excel(excel_file)\n",
        "\n",
        "            # Principio da rastreabilidade\n",
        "            # Nome do arquivo\n",
        "            df_temp['filename'] = os.path.basename(excel_file)\n",
        "\n",
        "            # Extração da localização da tabela\n",
        "            df_temp['location'] = df_temp['filename'].str.split('_')[-1]\n",
        "            df_temp['location'] = df_temp['location'].str.split('.')[0].str.lower()\n",
        "\n",
        "            # Extração de info sobre campaign - UTM\n",
        "            # df_temp = df_temp['utm_link'].str.split('utm_source=').str[-1]\n",
        "            df_temp = df_temp['utm_link'].str.extract(r'utm_campaign=(.*)')  # no extract recebe um padrão de regex\n",
        "\n",
        "            df_temp['campaign'] = df_temp[df_temp['utm_source'].notnull()]['utm_campaign']\n",
        "            df_temp['utm_source'] = df_temp[df_temp['utm_source'].notnull()]['utm_source']\n",
        "\n",
        "            # Conjunto de tabelas\n",
        "            dfs.append(df_temp)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Erro ao ler o arquivo {excel_file}: {e}')\n",
        "\n",
        "\n",
        "if len(dfs) != 0:\n",
        "    # Concatena todas as tabelas contidas no dfs em um única tabela\n",
        "    result = pd.concat( dfs, ignore_index=True)\n",
        "\n",
        "    # Cria o caminho da nova tabela tratada\n",
        "    output_file = os.path.join(os.getcwd(), 'src', 'data', 'ready', 'netflix_data_cleaned.xlsx')\n",
        "\n",
        "    # Criação da instância com especificação de motor (opcional)\n",
        "    writer = pd.ExcelWriter(output_file, engine='xlsxwriter')  # mudança do motor de escrita. XLSXWRITER pode ser mais performático\n",
        "\n",
        "    # Persistência da tabela em um arquivo excel e fechamento do arquivo\n",
        "    result.to_excel(writer, sheet_name='netflix_data_cleaned', index=False)\n",
        "    writer.save()\n",
        "    writer.close()\n",
        "else:\n",
        "    print('Nenhum dado para ser salvo')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}